{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import NMF\n",
    "import time\n",
    "import copy\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(np.random.choice([0,1],(100,20)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, ..., 1, 1, 1],\n",
       "       [1, 0, 1, ..., 1, 0, 1],\n",
       "       [1, 1, 1, ..., 1, 0, 1],\n",
       "       ...,\n",
       "       [0, 0, 1, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 1, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9993326356321898 0.0047724633550728646 0.4744848605751693 11.10587651389246\n",
      "0.9970518224489903 0.0010757902841025402 0.4363152034895211 4.696081830045622\n"
     ]
    }
   ],
   "source": [
    "#use the same init\n",
    "n_factors=4\n",
    "W0=np.random.random((X.shape[0],n_factors))\n",
    "H0=np.random.random((n_factors,X.shape[1]))\n",
    "print(W0.max(), W0.min(), W0.mean(), np.linalg.norm(W0))\n",
    "print(H0.max(), H0.min(), H0.mean(), np.linalg.norm(H0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 4) (4, 20)\n",
      "0.8534930074730912 0.0 0.26878123064509496 6.868154390442655\n",
      "2.457904908102121 0.0 0.48343643704125794 6.60419177612916\n",
      "{'alpha': 0.0, 'beta_loss': 'frobenius', 'init': 'custom', 'l1_ratio': 0.0, 'max_iter': 500, 'n_components': 4, 'random_state': None, 'shuffle': False, 'solver': 'cd', 'tol': 0.0001, 'verbose': 0}\n",
      "CPU times: user 15.6 ms, sys: 0 ns, total: 15.6 ms\n",
      "Wall time: 16.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n_factors=4\n",
    "nmf = NMF(n_components=n_factors, init='custom',max_iter=500)\n",
    "W = nmf.fit_transform(X,W=W0.astype(np.double),H=H0.astype(np.double)) #corresponding to the U matrix\n",
    "H = nmf.components_ #corresponding to the V matrix\n",
    "print(W.shape, H.shape)\n",
    "print(W.max(), W.min(), W.mean(), np.linalg.norm(W))\n",
    "print(H.max(), H.min(), H.mean(), np.linalg.norm(H))\n",
    "print(nmf.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "375"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmf.n_iter_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manual decomposition\n",
    "def updateU(X,U,V,n_factors,gamma=0.01):\n",
    "    perm = np.array(range(n_factors))\n",
    "    np.random.shuffle(perm)    \n",
    "    for k in perm:\n",
    "        for i in range(X.shape[0]):\n",
    "#             grad=0\n",
    "#             Z=0\n",
    "#             for j in range(X.shape[1]):\n",
    "#                 grad+=(X[i,j]-np.dot(U[i,:],V[:,j])+U[i,k]*V[k,j])*V[k,j]\n",
    "#                 Z += V[k,j]*V[k,j] \n",
    "            grad =  np.sum(V[k,:]*(X[i,:]-np.dot(U[i,:],V[:])+(U[i,k]*V[k,:])))   \n",
    "            Z = np.sum(np.square(V[k,:]))    \n",
    "            U[i,k]=U[i,k]+gamma*(grad/Z-U[i,k])  #moving average    \n",
    "    return U         \n",
    "\n",
    "def updateV(X,U,V, n_factors,gamma=0.01):\n",
    "    perm = np.array(range(n_factors))\n",
    "    np.random.shuffle(perm)\n",
    "    for k in perm:\n",
    "        for j in range(X.shape[1]):\n",
    "#             grad=0\n",
    "#             Z=0\n",
    "#             for i in range(X.shape[0]):\n",
    "#                 grad += (X[i,j]-np.dot(U[i,:],V[:,j])+U[i,k]*V[k,j])*U[i,k]\n",
    "#                 Z += U[i,k]*U[i,k]\n",
    "            grad =  np.sum(U[:,k]*(X[:,j]-np.dot(U[:],V[:,j])+V[k,j]*U[:,k]))   \n",
    "            Z = np.sum(np.square(U[:,k]))  \n",
    "            V[k,j]=V[k,j]+gamma*(grad/Z-V[k,j])   #moving average  \n",
    "            \n",
    "    return V\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NMF1(X,U,V,n_factors,itr=500,tol=0.0001,gamma=0.1):\n",
    "    i=0\n",
    "    ut = math.inf\n",
    "    vt = math.inf\n",
    "    while (i < itr)and((ut>tol)or(vt>tol)):\n",
    "        Uc = copy.deepcopy(U)\n",
    "        Vc = copy.deepcopy(V)\n",
    "        U = updateU(X, U, V, n_factors,gamma)\n",
    "        V = updateV(X, U, V, n_factors,gamma)\n",
    "        ut = np.linalg.norm(Uc-U)\n",
    "        vt = np.linalg.norm(Vc-V)\n",
    "        i+=1\n",
    "\n",
    "    meta=[i,ut,vt]    \n",
    "    return U, V, meta    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4256359486225392 -0.7353469841280715 0.33773175031711955 9.711463203731865\n",
      "1.0565875214032427 -0.28051829669813505 0.3539178638357291 4.361622729372063\n",
      "[500, 0.004303717022975672, 0.0018612614344892034]\n",
      "CPU times: user 4.17 s, sys: 0 ns, total: 4.17 s\n",
      "Wall time: 4.17 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n_factors=4\n",
    "U0 = copy.deepcopy(W0)\n",
    "V0= copy.deepcopy(H0)\n",
    "U, V, meta = NMF1(X,U0,V0, n_factors,itr=500,gamma=0.1)\n",
    "print(U.max(), U.min(), U.mean(), np.linalg.norm(U))\n",
    "print(V.max(), V.min(), V.mean(), np.linalg.norm(V)) \n",
    "print(meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.011676009680096841"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(W-U)/(W.shape[0]*W.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04298984278940894"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(H-V)/(H.shape[0]*H.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7353469841280715"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(W-U).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5553761178059644"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(H-V).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18365286237996753"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(W-U).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26195447960394697"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(H-V).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: The result is slightly different for the sklearn NMF and manual created NMF. It is because their optimization methods and regularization (thus also the loss function) are different, so the solutions they converge into can be a little different."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
